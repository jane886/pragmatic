1，年底了流行做年终总结，《北京市人工智能行业大模型创新应用白皮书(2023)》里说：
    「通用大模型趋于收敛，垂直行业应用成为大模型产业落地的关键赛道；当前大模型发展呈现出从技术到产品、
    再到商业化应用的发展路径，并不断深入垂直行业领域。」
    站在年底，回头看过去一年国产大模型领域的发展，百模大战轰轰烈烈，但说实话，给人一种热闹有余而生产力不足的感觉。
    特别是那些行业垂直模型，并没有达到预期效果，大模型在真实商业场景的潜力还远没有被充分挖掘。
    最近我深度体验了一下百川智能最新推出的基于搜索增强的Baichuan2-Turbo，感觉他们找对了路子，
    这也是百川在2024年即将到来之际，为大模型更低成本商用落地交出的年终答卷——大模型+搜索增强是大模型落地应用的完整技术栈。
    企业可以利用百川智能提供的开发套件方便快捷的构建专属知识库并搭建自己的专属应用。

2，大模型商业落地的难点&现有解决方案的不足
    大模型本身有很多优点和缺点，但聊起商业化落地，最重要的还是要和业务场景结合，与企业私有数据融合。
    
    垂直领域的业务数据是企业最核心的资产和竞争力，大模型如果不能与企业自有的知识库/数据库结合，
    能力再强的通用模型对企业来讲也毫无意义。
    
    现在企业如果想做大模型落地，普遍的做法是Post-train（后训练）和SFT（有监督训练），
    但这两种做法本质上依然是模型训练，自然需要专业技术团队、算力和数据，而这本来就是传统企业的短板。

    即便企业很重视大模型赋能，下决心把训练工作交给专业AI公司去做，得到最终效果往往也不尽如人意
    ——模型训练需要的时间长，而且微调训练并不能有效解决模型的幻觉问题，而且不论是基座模型更新还是数据更新，
    都需要重新做微调，难以保证实时的升级。总之，大模型商业落地，大家都想做，做好的没几个。

    百川解决方案的优势想要以更简便的方式把垂直领域的知识注入模型，并非没有其他思路——一拨人在搞向量数据库（VectorDB），
    也带火了很多投资，把向量数据库看做是大模型时代的存储新基座；另一拨人则转向RAG技术，优化增强模型检索外部信息的能力。
    这两种方法并不冲突，核心目的其实是一致的，那就是在不改变模型的情况下实现「知识外挂」。
    
    不过，同样是做RAG，模型之间亦有差别。想要更好地实现知识库外挂，就需要更长的窗口和更强的检索能力，
    这也是百川此次开放Baichuan2-Turbo系列API的优势所在。
    而百川认为，通过大模型+192k超长上下文窗口+搜索增强（互联网实时信息+企业私有数据）+可以解决99%企业定制化需求。
    听上去夸张，但我觉得有可能。百川目前支持同时上传20个文件，每个不超过50MB。


3，搜索增强是大模型时代的必由之路其实，搜索增强的解决方案是非常符合我们直觉的。
    不妨回忆一下人脑和计算机的类比关系——人脑是CPU，记忆相当于内存，其他保存在书本里的外部知识相当于硬盘。
    这样的结构，能保证我们最核心的思维能力，也可以平衡取存更快的「内存」和容量更大的「外存」——用到最多的知识记在脑子里，
    其他知识靠查询。常识告诉我们，内存要比硬盘贵得多的多。
    
    让大脑记住所有知识不现实也没必要，同理，将这套类比关系泛化到大模型领域，这些设定依然适用：
    大模型相当于CPU，对话窗口的Context上下文相当于内存，联网检索和离线知识库相当于外挂硬盘。

    这也正是百川提出的解决方案：在提供一流基座模型（CPU）的基础上，把模型上下文扩展到行业领先192k（内存），
    再通过搜索增强为模型外挂知识库（硬盘），以此用最低的成本实现高效率、高质量的信息处理，让大模型能够更好地利用外部知识，
    提升应用潜力，解决幻觉、时效性、私有数据、模型升级等问题。


4，能给行业带来什么
    从企业的角度来说，他们依靠自身在领域内多年的积累，掌握着行业内非常有价值的高质量数据。
    如何把这些珍贵的数据“教给”大模型，然后再从大模型中收益，是很多企业的迫切需求。
    
    过去最普遍的做法是用行业数据对大模型微调，但上文也提到了，这种方式技术成本、时间成本和金钱成本都很高，
    导致很少有企业负担得起。同时时效性和灵活性方面都很差。
    
    百川智能的“大模型+搜索增强”方案给我的最大感受是他们在SFT这条道路之外探索出一条新的道路。
    “大模型+搜索增强”在解决行业模型定制问题上的优势可以用5个字概括。
        新：依靠增强数据库，大模型可以生成最新的企业实时数据&知识。
        快：新增数据可以随时存入企业知识库，以非参数化的知识提供给大模型，不用SFT训练。
        准：基于知识库生成的内容信息准确，大幅减弱幻觉现象的发生。
        全：结合百川搜索增强技术的优势，知识召回更全，大模型生成的内容也更全面。
        省：使用知识库的成本远低于fine-tune所需的成本。
    
    可以说，这样的大模型+搜索增强技术方案能解决99%的企业定制需求，同时保证了灵活、高效、降低幻觉等特性，
    可随模型能力上升无缝升级。目前世界范围来说，模型底层架构短期很难有重大突破。以百川为代表的技术型大模型初创公司，
    在“长窗口“、”搜索增强”等技术上的突破可以让现有模型能力高效便捷的转化为企业落地应用，是很好的探索和发展方向。


