langchain

背景：
  在互联网时代，海量的数据存储于数据库中，各家公司对于客户数据价值的挖掘显然能够帮助企业做出更好的商业决策，提高竞争力。
  众所周知，OpenAI这种类似的LLMs是通过公开的数据集进行训练的，公司/组织的私有数据集和垂直行业的知识库以及互联网上的最新数据集都是不具备的。
  如何才能让LLMs学习这些知识，成为了大家热衷追逐的话题。目前主要有两种方式: 
    Fine-tuning
    in-context learning（上下文学习）
  
  Fine-tuning相对麻烦，需要算法工程师通过训练的方式，使模型永久记忆，门槛较高，很多人/公司不具备这样的能力。
  in-context learning是通过Prompt，利用LLM的理解和推理的能力，让模型生成答案。
  
  相比较之下，in-context learning 时间更短，成本也更低。
  
  本文主要介绍下in-context learning 的方式，主要介绍一下LangChain这个框架，以及它比较Cool的一些特性。


介绍：
  LangChain 是一个用于开发由语言模型驱动的应用程序的框架。
  日常的真实场景中，需要解决的问题是复杂多变的，有价值和差异化的应用程序不仅会通过 API 调用语言模型，而且还会：
    数据感知：将语言模型连接到其他数据源
    Be agentic: 允许语言模型与其环境交互

  解决现实中真实的问题。就是为这个思想而设计的。
  langchain主要有6个模块组成，分别是: Models，Prompts，Indexes，Memory，Chains，Agents。
  我大致把他们分成3层：基础层，能力层，应用层。

  基础层：Models，Indexes
    Models 
      该模块是langchain的核心，Langchain不提供模型，而是提供标准的接口。提供常用模型的封装/集成。如OpenAI，HuggingFace等。

      目前主要集成/封装的模型有三类：

        LLMs 
        这一层主要强调对model层能力的封装以及服务化输出能力，目前主要有 OpenAI，Hugging Face，Modal等24家的封装。

        Chat Models
        这块主要是LLM的变体，界面和以及输入输出不同。从【文本输入，文本输出】→  【聊天消息的输入和输出】，这块内容还在寻找正确的抽象。

        Text Embedding Models
        Embedding 是一段文本的矢量表示，基于向量空间，我们可以进行语义搜索之类的操作，可以在向量空间中寻找最相似的文本片段。
        已集成OpenAI，Cohere，Hugging Face等12家。

      原理：使用模版，工厂等设计模式+复写等策略实现多态的一种形式，
      1.  各类LLM模型管理，强调模型的种类丰富以及易用性。2. 一体化服务产品的能力，强调开箱即用。
      （开箱即用功能（out-of-the-box feature，也称OOTB或off the shelf）在软件上指产品在安装后，
       无需配置或修改，即可使用的功能或特性。 也指默认即对所有用户可用，不需支付额外费用或进行另外的配置。）

    Indexes
      该模块包含用于处理文档、不同类型索引的实用函数，主要用于摘要的生成，文本数据的向量化，以及在对话场景中的prompt。
      框架最大的优势在于抽象了文档加载的接口，让我们开箱即用。尽管目前针对某些加载器并不支持，我们完全可以在遵从框架的前提下自己编写。
      主要提供如下模块：
        * 文档加载器
        * 文本拆分器
        * 向量存储
        * Retrievers检索器

  能力层：Memory，Chains层，Tools层
    Prompts
      当我们与LLMs模型交互的时候，输入的文本被称为prompt。
      通常这不是简单的hardcode字符串，而是模版，一些实例+ 用户输入的组合。我们通过一些简单的实例，来展示下LangChain框架帮我们做了什么。

      原理： 字符串的拼接组合形成新的Prompt。

    Memory
      默认Chains和Agents都是无状态的，意味着每次处理都是一个单独的请求，底层的LLM的模型也是这样。
      特别是在聊天的场景中，记录上下文信息非常重要，无论是短期的还是长期的。 “Memory”的概念正是为了做到这一点而存在的。

      LangChain 提供两种形式的记忆组件，[怎么对应？]。BufferMemory和SummaryMemory。
      使用该模块可以非常方便的管理和操作以前的聊天记录。并且提供了合并到chains的简单方法。

      原理：在内存中配合其他的chain拼接history字符串，形成一个prompts。

    Chains
      Chain是一个使用LLM对于处理简单的场景是非常好的，但更多的场景是比较复杂的，需要LLMs和其他专业的多个Chain组合成一个Chains链。
      LangChain提供了Chains的标准接口，以及一些常见的Chain。

        Chain = Models + Prompts + 任意函数
        Chains = Chain + Chain + ...
        
      它允许我们将多个组件组合在一起以创建一个单一的、连贯的应用程序。
          
      原理： 单个任务Chain的组合，形成一个可以应对更为复杂的，多变的应用场景的Chains。

    应用层：Agents
      Agents
      Langchain是工具/框架，是对LLM的周边进行接口定义及封装。 
      任何固定的Chains以及Prompts都是没有灵魂的，在2.0时代，我们完全可以赋予其灵魂，让LLM自己做决策，也可以通过Agents加入外部的控制，比如操纵传感器，开关，摄像头等。
      任何简单单边的控制都是有局限的，只有可以一起配合才能做成一个复杂系统。