
1.SFT 监督微调

    1.1 SFT 监督微调基本概念
    SFT（Supervised Fine-Tuning）监督微调是指在源数据集上预训练一个神经网络模型，即源模型。
    然后创建一个新的神经网络模型，即目标模型。
    目标模型复制了源模型上除了输出层外的所有模型设计及其参数。
    这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。
    源模型的输出层与源数据集的标签紧密相关，因此在目标模型中不予采用。
    微调时，为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。
    在目标数据集上训练目标模型时，将从头训练到输出层，其余层的参数都基于源模型的参数微调得到。

    1.2 监督微调的步骤
    具体来说，监督式微调包括以下几个步骤：

    预训练： 首先在一个大规模的数据集上训练一个深度学习模型，例如使用自监督学习或者无监督学习算法进行预训练；
    微调： 使用目标任务的训练集对预训练模型进行微调。通常，只有预训练模型中的一部分层被微调，例如只微调模型的最后几层或者某些中间层。
        在微调过程中，通过反向传播算法对模型进行优化，使得模型在目标任务上表现更好；
    评估： 使用目标任务的测试集对微调后的模型进行评估，得到模型在目标任务上的性能指标。
    
    1.3 监督微调的特点
    监督式微调能够利用预训练模型的参数和结构，避免从头开始训练模型，从而加速模型的训练过程，并且能够提高模型在目标任务上的表现。
    监督式微调在计算机视觉、自然语言处理等领域中得到了广泛应用。
    然而监督也存在一些缺点。首先，需要大量的标注数据用于目标任务的微调，如果标注数据不足，可能会导致微调后的模型表现不佳。
    其次，由于预训练模型的参数和结构对微调后的模型性能有很大影响，因此选择合适的预训练模型也很重要。


2，SFT（Sparse Fine-Tuning）是一种使用有监督学习来微调预训练语言模型的模型。
    SFT 模型的目标是使预训练语言模型（如GPT-3、BERT等）能够更好地完成特定的任务。
    他的工作原理是将预训练语言模型作为基础，然后使用有监督学习来调整模型的参数。有监督学习是指使用带标签的数据来训练模型。
    在 SFT 模型中，标签通常是目标任务的正确答案。
    
    以下是全面了解SFT模型的几个关键点：
        1，基本概念： SFT是一种只对预训练模型的一小部分参数进行调整的微调技术。
            这种方法的目的是在保持大部分预训练知识的同时，使模型适应特定任务或数据集。
        2，稀疏性原理： 在SFT中，"稀疏"指的是只有一小部分权重（模型参数）被更新。
            这与传统的微调方法相对，后者通常更新所有权重。稀疏性有助于减少过拟合的风险，特别是在数据较少的情况下。
        3，实现方法： 实现SFT通常涉及选择哪些权重进行更新。这可以通过各种技术实现，如基于梯度的方法、基于注意力的选择或其他启发式方法。
        4，应用场景： SFT特别适用于资源受限的情况，例如当计算资源有限或可用于训练的数据量较少时。
            它也适用于需要高度定制化模型的场景，但又不想从头开始训练整个模型。
        5，优势和局限性： SFT的主要优势是效率和灵活性。它允许快速调整模型以适应新任务，同时减少计算成本。
            然而，它的效果可能依赖于正确选择哪些权重进行更新，这可能需要专业知识和实验。
            
    SFT 模型的优点在于能够快速提高预训练语言模型在特定任务上的性能。
    SFT 模型的缺点在于需要有标签的数据来训练模型，这可能导致标签偏差。
    
    实现Sparse Fine-Tuning（SFT）通常涉及以下几个步骤：
        1，选择基础模型： 首先，选择一个适合你任务的预训练语言模型，如BERT、GPT-3或其他类似模型。这个模型将作为SFT的起点。
        2，定义稀疏性策略： 决定哪些参数将被更新是SFT的关键。这可以基于不同的策略，
            例如：基于梯度的选择： 选择对模型输出影响最大的参数。
                基于注意力的选择： 在基于Transformer的模型中，选择最活跃的注意力头。
                随机选择： 随机选择一定比例的参数进行更新。
                专家知识： 根据对模型架构的理解，选择特定的层或参数进行更新。
        3.准备数据集： 准备用于微调的数据集。这应该是针对你的特定任务或应用场景的数据。
        4.微调过程： 使用你的数据集对选定的参数进行微调。这通常涉及以下步骤：
            损失函数： 定义一个适合你任务的损失函数，如交叉熵损失用于分类任务。
            优化器： 选择一个优化器，如Adam或SGD，并设置适当的学习率。
            训练循环： 在训练循环中，只更新你在稀疏性策略中选择的参数。确保其他参数保持不变。
        5.评估和调整： 在验证集上评估模型性能。根据需要调整稀疏性策略、学习率或其他超参数。
        6.部署： 一旦模型达到满意的性能，就可以将其部署到生产环境中。