Self-attention

自注意力是机器学习中使用的一种机制，特别是在自然语言处理 (NLP) 和计算机视觉任务中，用于捕获输入序列中的依赖性和关系。
它允许模型通过关注自身来识别和权衡输入序列不同部分的重要性。

注意力机制是人工神经网络中一种模仿认知注意力的技术。
这种机制可以增强神经网络输入数据中某些部分的权重，同时减弱其他部分的权重，以此将网络的关注点聚焦于数据中最重要的一小部分。
数据中哪些部分比其他部分更重要取决于上下文。可以通过梯度下降法对注意力机制进行训练。 

